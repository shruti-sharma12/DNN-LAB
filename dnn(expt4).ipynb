{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt+2u1aom8ZYV1Fo+0k0Ez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shruti-sharma12/DNN-LAB/blob/main/dnn(expt4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAME: SHRUTI SHARMA\n",
        "\n",
        "PRN:1032211936\n",
        "\n",
        "EXPERIMENT 4"
      ],
      "metadata": {
        "id": "1j1xfJKdFMGj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1SeKD0AEutT",
        "outputId": "ff123667-3b4d-4900-cc02-cdf25da4072f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class RBFN:\n",
        "    def __init__(self, num_rbf_neurons, sigma=1.0):\n",
        "        self.num_rbf_neurons = num_rbf_neurons\n",
        "        self.sigma = sigma\n",
        "        self.centers = None\n",
        "        self.weights = None\n",
        "\n",
        "    def _gaussian(self, x, center):\n",
        "        return np.exp(-np.sum((x - center) ** 2) / (2 * self.sigma ** 2))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Step 1: Select centers of the RBF nodes from the training samples\n",
        "        self.centers = X[np.random.choice(X.shape[0], self.num_rbf_neurons, replace=False)]\n",
        "\n",
        "        # Step 2: Calculate the radial basis function values\n",
        "        G = np.zeros((X.shape[0], self.num_rbf_neurons + 1))\n",
        "        for i, x in enumerate(X):\n",
        "            for j, center in enumerate(self.centers):\n",
        "                G[i, j] = self._gaussian(x, center)\n",
        "            G[i, -1] = 1  # Bias term\n",
        "\n",
        "        # Step 8: Calculate pseudo-inverse of matrix G\n",
        "        G_pseudo_inv = np.linalg.pinv(G)\n",
        "\n",
        "        # Step 9: Calculate weights\n",
        "        self.weights = np.dot(G_pseudo_inv, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        G = np.zeros((X.shape[0], self.num_rbf_neurons + 1))\n",
        "        for i, x in enumerate(X):\n",
        "            for j, center in enumerate(self.centers):\n",
        "                G[i, j] = self._gaussian(x, center)\n",
        "            G[i, -1] = 1  # Bias term\n",
        "        return np.dot(G, self.weights)\n",
        "\n",
        "\n",
        "# XOR gate truth table\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "# Create and train RBFN\n",
        "rbfn = RBFN(num_rbf_neurons=2, sigma=1)\n",
        "rbfn.fit(X, y)\n",
        "\n",
        "# Predict output for XOR gate\n",
        "predictions = rbfn.predict(X)\n",
        "print(\"Predictions:\", np.round(predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post Lab Questions:\n",
        "\n",
        "Q1. Name and Explain the mapping functions that can be used in Radial Basis Function Network training.\n",
        "\n",
        "Ans. In Radial Basis Function (RBF) Networks, mapping functions play a crucial role in transforming the input data into a form suitable for learning. These mapping functions are primarily used in the hidden layer of the RBF network to transform input patterns into a high-dimensional feature space. Here are some common mapping functions used in RBF networks:\n",
        "\n",
        "1. **Gaussian Function**: The Gaussian function is one of the most commonly used mapping functions in RBF networks. It transforms the input pattern into a high-dimensional space where the distance between the input pattern and the center of each RBF neuron is measured using the Gaussian function. The Gaussian function is given by:\n",
        "\n",
        "   \\[ \\phi_i(\\mathbf{x}) = \\exp \\left( -\\frac{\\|\\mathbf{x} - \\mathbf{c}_i\\|^2}{2\\sigma_i^2} \\right) \\]\n",
        "\n",
        "   where \\( \\phi_i(\\mathbf{x}) \\) is the output of the \\(i\\)-th RBF neuron, \\( \\mathbf{x} \\) is the input pattern, \\( \\mathbf{c}_i \\) is the center of the \\(i\\)-th RBF neuron, and \\( \\sigma_i \\) is the spread or width parameter of the Gaussian function.\n",
        "\n",
        "2. **Multiquadric Function**: The multiquadric function is another commonly used mapping function in RBF networks. It is similar to the Gaussian function but uses the square root of the sum of squares instead of the Euclidean distance. The multiquadric function is given by:\n",
        "\n",
        "   \\[ \\phi_i(\\mathbf{x}) = \\sqrt{\\|\\mathbf{x} - \\mathbf{c}_i\\|^2 + \\beta_i^2} \\]\n",
        "\n",
        "   where \\( \\phi_i(\\mathbf{x}) \\) is the output of the \\(i\\)-th RBF neuron, \\( \\mathbf{x} \\) is the input pattern, \\( \\mathbf{c}_i \\) is the center of the \\(i\\)-th RBF neuron, and \\( \\beta_i \\) is a scaling parameter.\n",
        "\n",
        "3. **Inverse Multiquadric Function**: This function is the inverse of the multiquadric function and is given by:\n",
        "\n",
        "   \\[ \\phi_i(\\mathbf{x}) = \\frac{1}{\\sqrt{\\|\\mathbf{x} - \\mathbf{c}_i\\|^2 + \\beta_i^2}} \\]\n",
        "\n",
        "   It has similar properties to the multiquadric function but may behave differently in certain cases.\n",
        "\n",
        "4. **Thin Plate Spline Function**: The thin plate spline function is a radial basis function commonly used in interpolation problems. It is defined as:\n",
        "\n",
        "   \\[ \\phi_i(\\mathbf{x}) = \\|\\mathbf{x} - \\mathbf{c}_i\\|^2 \\log(\\|\\mathbf{x} - \\mathbf{c}_i\\|) \\]\n",
        "\n",
        "   This function has properties suitable for smoothing and interpolation tasks.\n",
        "\n",
        "These mapping functions are used to compute the activations of the hidden layer neurons in an RBF network. Each neuron typically corresponds to a center point in the input space, and the output of the neuron indicates the similarity between the input pattern and the center point. These activations are then weighted and combined in the output layer to produce the final output of the network."
      ],
      "metadata": {
        "id": "-LKHTMRpIPFK"
      }
    }
  ]
}