{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5WBegDwI3LEv0KM2juyUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shruti-sharma12/DNN-LAB/blob/main/dnn(expt3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAME: SHRUTI SHARMA\n",
        "\n",
        "PRN:1032211936\n",
        "\n",
        "DATE: 12/02/2024\n",
        "\n",
        "EXPERIMENT 3"
      ],
      "metadata": {
        "id": "OL7LWNypt2Br"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwdFVVSul7Kw"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#given input data\n",
        "I1=np.array([[0.4],[0.3],[0.6],[0.2]])\n",
        "I2=np.array([[-0.7],[-0.5],[0.1],[0.4]])\n",
        "\n",
        "#given target output\n",
        "O=np.array([[0.1],[0.05],[0.3],[0.25]])\n",
        "\n",
        "#given initial weight\n",
        "Vo=np.array([[0.1,0.4],[-0.2,0.2]])\n",
        "Wo=np.array([[0.2],[-0.5]])\n",
        "\n",
        "#learning rate\n",
        "alpha=0.01\n",
        "\n",
        "#no. of iterations\n",
        "num_iterations=100\n",
        "\n",
        "#activation function(sigmoid)\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "#derivative of sigmoid\n",
        "def sigmoid_derivative(x):\n",
        "  return x*(1-x)\n",
        "\n",
        "#initialize weights\n",
        "v=Vo\n",
        "w=Wo\n",
        "\n",
        "#training loop\n",
        "for iteration in range(num_iterations):\n",
        "  total_error=0\n",
        "\n",
        "  #iterate through each training pair\n",
        "  for i in range(len(O)):  # Iterate over the size of the target output\n",
        "    #feedforward\n",
        "    input_hidden=I1[i][0]*v[0,0]+I2[i][0]*v[1,0]\n",
        "    output_hidden=sigmoid(input_hidden)\n",
        "\n",
        "    input_output=np.dot(output_hidden,w)\n",
        "    output_network=sigmoid(input_output)\n",
        "\n",
        "    #calculate error\n",
        "    error = O[i]-output_network\n",
        "    total_error+=np.sum(error**2)\n",
        "\n",
        "    #backpropagation\n",
        "    delta_output=error*sigmoid_derivative(output_network)\n",
        "    delta_hidden=delta_output.dot(w.T)*sigmoid_derivative(output_hidden)\n",
        "\n",
        "    #update weights\n",
        "    w+=alpha*output_hidden.reshape(-1,1)*delta_output\n",
        "    v[0]+=alpha*I1[i]*delta_hidden[0]\n",
        "    v[1]+=alpha*I2[i]*delta_hidden[0]  #corrected line\n",
        "\n",
        "  #print total error for monitoring convergence\n",
        "  if iteration %100==0:\n",
        "    print(f\"Iteration:{iteration},Total Error:{total_error}\")\n",
        "\n",
        "#print final weights\n",
        "print(\"\\nFinal Weights:\")\n",
        "print(\"Vo: \")\n",
        "print(v)\n",
        "print(\"Wo: \")\n",
        "print(w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcak4g6BmeD5",
        "outputId": "a93a5334-6bec-4099-e742-cf5331f9998d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:0,Total Error:0.8477222998981543\n",
            "\n",
            "Final Weights:\n",
            "Vo: \n",
            "[[ 0.09662273  0.41708332]\n",
            " [-0.19725181  0.18615046]]\n",
            "Wo: \n",
            "[[ 0.02266641]\n",
            " [-0.62950794]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POST LAB QUESTIONS:\n",
        "\n",
        "2. Explain the method to initialize weights for a Back-propagation network.\n",
        "\n",
        "Ans:   Initializing weights properly in a back-propagation neural network is crucial for effective learning and convergence during training. Here's a general method to initialize weights:\n",
        "\n",
        "Understand Network Architecture: First, you need to understand the architecture of your neural network, including the number of layers, the number of neurons in each layer, and the connectivity pattern between layers.\n",
        "\n",
        "Determine Weight Matrix Sizes: Once you understand the architecture, you can determine the sizes of weight matrices connecting the neurons in adjacent layers.\n",
        "\n",
        "Select Initialization Method: There are several methods for initializing weights. Some common ones include:\n",
        "\n",
        "Random Initialization: Initialize weights randomly from a uniform or normal distribution. This is a simple method but may lead to slow convergence or vanishing/exploding gradients, especially in deeper networks.\n",
        "\n",
        "Xavier/Glorot Initialization: This method initializes weights from a Gaussian distribution with zero mean and variance scaled based on the number of input and output neurons. It helps mitigate the vanishing/exploding gradient problem, especially in deep networks.\n",
        "\n",
        "He Initialization: Similar to Xavier initialization but with a different scaling factor, particularly suitable for networks using activation functions like ReLU.\n",
        "\n",
        "Custom Initialization: Depending on the specific characteristics of your network and the activation functions you're using, you might develop custom initialization methods.\n",
        "\n",
        "Initialize Weights: Once you've chosen a method, you can initialize the weights of your neural network accordingly. Initialize each weight matrix with the chosen initialization method.\n",
        "\n",
        "Bias Initialization: Don't forget to initialize the biases as well. Biases can be initialized to zero or small random values.\n",
        "\n",
        "Fine-Tuning: After initializing weights, you might need to fine-tune them during training using techniques like batch normalization or adaptive learning rate methods.\n",
        "\n",
        "Regularization: Optionally, you can apply weight regularization techniques such as L1 or L2 regularization to prevent overfitting during training.\n",
        "\n",
        "Experimentation and Tuning: Finally, experimentation and tuning might be necessary to find the optimal initialization method and other hyperparameters for your specific network architecture and training dataset.\n",
        "\n",
        "3. Explain the choice of learning rate parameter.\n",
        "\n",
        "Ans: The learning rate is a crucial hyperparameter in training neural networks using optimization algorithms like gradient descent or its variants (e.g., stochastic gradient descent, Adam). It determines the size of the step taken during each iteration to update the weights of the network. Here's an explanation of how the choice of learning rate parameter impacts the training process:\n",
        "\n",
        "Impact on Convergence:\n",
        "A learning rate that is too small may lead to slow convergence. The model will take tiny steps during each iteration, prolonging the training process.\n",
        "Conversely, a learning rate that is too large may cause the optimization algorithm to overshoot the optimal solution. This can lead to divergence, where the loss increases rather than decreases over time.\n",
        "\n",
        "Finding a Balance:\n",
        "The choice of learning rate involves finding a balance between convergence speed and stability. It should be large enough to converge efficiently but small enough to prevent divergence.\n",
        "The ideal learning rate can vary depending on factors such as the network architecture, the complexity of the problem, and the scale of the dataset.\n",
        "\n",
        "Impact on Performance:\n",
        "A well-tuned learning rate can significantly impact the performance of the trained model. It can affect both the final accuracy and the time taken to reach convergence.\n",
        "In practice, it's common to start with a moderate learning rate and adjust it based on the observed behavior during training.\n",
        "\n",
        "Learning Rate Scheduling:\n",
        "Learning rate scheduling techniques can be employed to adaptively adjust the learning rate during training. Common approaches include decreasing the learning rate over time (e.g., using a learning rate decay schedule) or dynamically adjusting it based on performance metrics (e.g., using techniques like AdaGrad, RMSprop, or Adam).\n",
        "\n",
        "Exploration vs. Exploitation:\n",
        "During early stages of training, a higher learning rate might allow the model to explore the parameter space more quickly, while during later stages, a smaller learning rate might be necessary for fine-tuning and convergence.\n",
        "\n",
        "Empirical Testing:\n",
        "Choosing an appropriate learning rate often involves empirical testing. It's common to try a range of learning rates and monitor the training process (e.g., loss curve, validation accuracy) to determine the most suitable value.\n",
        "\n",
        "4. Explain what do you mean by Generalization.\n",
        "\n",
        "Ans: Generalization in the context of machine learning refers to the ability of a trained model to perform well on new, unseen data that it hasn't encountered during training. In essence, a model that generalizes well can effectively capture the underlying patterns in the data and make accurate predictions or classifications for data points it hasn't been explicitly trained on.\n",
        "\n",
        "Learning from Training Data: During the training process, a machine learning model learns from a dataset that typically consists of input-output pairs. The model adjusts its parameters (e.g., weights in a neural network) to minimize a loss function, effectively capturing patterns in the training data.\n",
        "\n",
        "Applying Learned Patterns to New Data: The goal of training a machine learning model is not just to memorize the training data but to learn generalizable patterns that can be applied to new, unseen data. Generalization occurs when the model can accurately predict or classify new data points based on these learned patterns.\n",
        "\n",
        "Avoiding Overfitting: One of the key challenges in machine learning is avoiding overfitting, where a model learns to memorize the training data rather than capturing underlying patterns. Overfitting can occur when a model is too complex relative to the amount of training data, leading to poor generalization performance on new data.\n",
        "\n",
        "Evaluation on Test Data: To assess the generalization performance of a trained model, it is common practice to evaluate its performance on a separate dataset called the test set. This test set contains data that the model hasn't seen during training. The performance metrics calculated on the test set, such as accuracy, precision, recall, or F1 score, provide insights into how well the model generalizes to new data.\n",
        "\n",
        "Cross-Validation: In addition to using a separate test set, cross-validation techniques such as k-fold cross-validation can be employed to assess generalization more robustly. These techniques involve splitting the dataset into multiple folds, training the model on different subsets of the data, and evaluating its performance across multiple iterations.\n",
        "\n",
        "Regularization: Techniques like L1 and L2 regularization can help improve generalization by penalizing overly complex models during training, thereby reducing the risk of overfitting."
      ],
      "metadata": {
        "id": "82SD876xuJli"
      }
    }
  ]
}